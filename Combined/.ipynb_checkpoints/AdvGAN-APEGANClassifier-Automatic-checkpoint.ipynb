{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MNIST Data Pre-processing\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils  # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = np_utils.to_categorical(y_train, 10).astype(np.float32)\n",
    "y_test = np_utils.to_categorical(y_test, 10).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8, A : adv acc:0.0083, rct1 acc:0.0370, rct2 acc:0.0247\n",
      "8, B : adv acc:0.0059, rct1 acc:0.0110, rct2 acc:0.0386\n",
      "8, C : adv acc:0.0291, rct1 acc:0.0392, rct2 acc:0.0216\n",
      "9, A : adv acc:0.2048, rct1 acc:0.3250, rct2 acc:0.2734\n",
      "9, B : adv acc:0.0003, rct1 acc:0.0543, rct2 acc:0.1177\n",
      "9, C : adv acc:0.1378, rct1 acc:0.2291, rct2 acc:0.2376\n"
     ]
    }
   ],
   "source": [
    "from AdvGAN import AdvGAN_APEGANClassifier\n",
    "\n",
    "GAN, G, D, APEG, F = AdvGAN_APEGANClassifier([28,28,1], 'B', 2, 2, 1)\n",
    "\n",
    "epochs=500\n",
    "batch_size=256\n",
    "\n",
    "for target in [8, 9]:\n",
    "    for cur_epoch in range(epochs):\n",
    "        for discrm_epoch in range(8):\n",
    "            input_batch = x_train[np.random.randint(0, x_train.shape[0], size=int(batch_size)),]\n",
    "            y_discrim = np.ones([batch_size,1])\n",
    "            if discrm_epoch % 2 == 0:\n",
    "                input_batch = np.add(input_batch, G.predict(input_batch))\n",
    "                y_discrim = np.zeros([batch_size,1])\n",
    "            D.train_on_batch(input_batch, y_discrim)\n",
    "\n",
    "        input_idx = np.random.randint(0, x_train.shape[0], size=int(batch_size))\n",
    "        input_batch = x_train[input_idx,]\n",
    "        y_discrim = np.ones([batch_size,1])\n",
    "        y_class=np_utils.to_categorical(np.ones(batch_size)*target, 10).astype(np.float32)\n",
    "        y_hinge=np.zeros([batch_size,28,28,1])\n",
    "        scalarloss=GAN.train_on_batch(input_batch, [y_discrim, y_class, y_class, y_hinge])\n",
    "        #print(\"Epoch number:\",cur_epoch,\"; Loss\",scalarloss)\n",
    "\n",
    "    clean = x_test\n",
    "    adv = clean + G.predict(clean)\n",
    "    label = np.argmax(y_test, axis=1)\n",
    "    idx = (label != target)\n",
    "    clean = clean[idx,]\n",
    "    adv = adv[idx,]\n",
    "    label = label[idx,]\n",
    "\n",
    "    classifier_name = ['A', 'B', 'C']\n",
    "    APECWG = keras.models.load_model('./models/APEGAN-CW-G.h5')\n",
    "    for cn in classifier_name:\n",
    "        BF = keras.models.load_model('../AdvGAN/models/Classifier-' + cn + '.h5')\n",
    "        adv_pdt = np.argmax(BF.predict(adv), axis=1)\n",
    "        purified1_pdt = np.argmax(BF.predict(APEG.predict(adv)), axis=1)\n",
    "        purified2_pdt = np.argmax(BF.predict(APECWG.predict(adv)), axis=1)\n",
    "        print('{}, {} : adv acc:{:.4f}, rct1 acc:{:.4f}, rct2 acc:{:.4f}'.format(\n",
    "            target, cn, np.mean(adv_pdt==label), np.mean(purified1_pdt==label),\n",
    "            np.mean(purified2_pdt==label)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
