# 6.883Project
6.883 Spring 2018 Project Repository

## Papers
#### Finished
 - [Propoal](https://github.com/johnding1996/6.883Project/blob/master/docs/proposal.pdf)
 - [Mid-Porject](https://github.com/johnding1996/6.883Project/blob/master/docs/midproject.pdf)
 - [Final-Porject](https://github.com/johnding1996/6.883Project/blob/master/docs/finalproject.pdf)

#### ShareLatex (readonly)
 - [Propoal](https://www.sharelatex.com/read/cpnytmwmcfjs)
 - [Mid-Porject](https://www.sharelatex.com/read/xmkkbgjqsqzr)
 - [Final-Porject](https://www.sharelatex.com/read/ygtrykqqgtcq)

## Reference Papers
### Core
1. [Generating Adversarial Examples with Adversarial Networks](https://arxiv.org/abs/1801.02610) C. Xiao, B. Li, J.-Y. Zhu, W. He, M. Liu, and D. Song, arXiv preprint arXiv:1801.02610 (2018).
2. [APE-GAN: Adversarial Perturbation Elimination with GAN](https://arxiv.org/abs/1707.05474) S. Shen, G. Jin, K. Gao, and Y. Zhang, ICLR Submission (2017).
3. [Defence-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models](https://openreview.net/forum?id=BkJ3ibb0-&noteId=SJwPXJaHG) P. Samangouei, M. Kabkab, and R. Chellappa (2018).
4. [The Robust Manifold Defense Adversarial Training Using Generative Models](https://arxiv.org/abs/1712.09196) A. Ilyas, A. Jalal, E. Asteri, C. Daskalakis, and A. G. Dimakis, arXiv preprint arXiv:1712.09196 (2017).
### Evluation
5. [MagNet and "Efficient Defenses Against Adversarial Attacks" are Not Robust to Adversarial Examples](https://arxiv.org/abs/1711.08478) N. Carlini and D. Wagner, “Magnet and” efficient defenses
against adversarial attacks” are not robust to adversarial examples,” arXiv preprint arXiv:1711.08478, 2017.
6. [Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](https://arxiv.org/abs/1802.00420) A. Athalye, N. Carlini, and D. Wagner, “Obfuscated gradients
give a false sense of security: Circumventing defenses to adversarial examples,” arXiv preprint arXiv:1802.00420, 2018.
7. [Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083) A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu,
“Towards deep learning models resistant to adversarial attacks,”
arXiv preprint arXiv:1706.06083, 2017.
### Comparison Metrics
8. [Provably Minimally Distorted Adversarial Examples](https://arxiv.org/abs/1709.10207) N. Carlini, G. Katz, C. Barrett, and D. L. Dill, arXiv preprint arXiv:1709.10207 (2017).

## Related Repositories
 - [cleverhans](https://github.com/tensorflow/cleverhans)
 - [APE-GAN](https://github.com/shenqixiaojiang/APE-GAN)
 - [defense-gan](https://github.com/anishathalye/obfuscated-gradients/tree/master/defensegan)
